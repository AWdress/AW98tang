#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ›´æ–°ç®¡ç†æ¨¡å—
"""
import os
import subprocess
import json
import requests
import logging
from datetime import datetime
import shutil
import zipfile
import tempfile

class UpdateManager:
    def __init__(self):
        self.current_version = self.get_current_version_from_readme()
        self.repo_owner = "AWdress"
        self.repo_name = "AW98tang"
        self.github_api = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}"
        self.branch = "main"
        
    def get_current_version_from_readme(self):
        """ä»æœ¬åœ°README.mdè¯»å–å½“å‰ç‰ˆæœ¬ï¼ˆä» ## ğŸ”¥ æœ€æ–°æ›´æ–° æ ‡é¢˜æå–ï¼‰"""
        try:
            with open('README.md', 'r', encoding='utf-8') as f:
                content = f.read()
                # åŒ¹é…æ ¼å¼ï¼š## ğŸ”¥ æœ€æ–°æ›´æ–°ï¼ˆv3.7ï¼‰æˆ– ## ğŸ”¥ æœ€æ–°æ›´æ–°ï¼ˆv3.7.1ï¼‰
                import re
                match = re.search(r'##\s*ğŸ”¥\s*æœ€æ–°æ›´æ–°[ï¼ˆ(](v[\d.]+)[ï¼‰)]', content)
                if match:
                    return match.group(1)
        except Exception as e:
            logging.warning(f"æ— æ³•ä»READMEè¯»å–ç‰ˆæœ¬: {e}")
        return "v3.7"  # é»˜è®¤ç‰ˆæœ¬
    
    def get_remote_version_from_readme(self):
        """ä»GitHubè¿œç¨‹README.mdè¯»å–æœ€æ–°ç‰ˆæœ¬å·"""
        try:
            headers = {}
            github_token = os.getenv('GITHUB_TOKEN')
            if github_token:
                headers['Authorization'] = f'token {github_token}'
            
            # ä½¿ç”¨ raw.githubusercontent.com ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹
            raw_url = f"https://raw.githubusercontent.com/{self.repo_owner}/{self.repo_name}/{self.branch}/README.md"
            response = requests.get(raw_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                content = response.text
                import re
                match = re.search(r'##\s*ğŸ”¥\s*æœ€æ–°æ›´æ–°[ï¼ˆ(](v[\d.]+)[ï¼‰)]', content)
                if match:
                    remote_version = match.group(1)
                    logging.info(f"ä»GitHubè¯»å–åˆ°æœ€æ–°ç‰ˆæœ¬: {remote_version}")
                    return remote_version
        except Exception as e:
            logging.warning(f"ä»GitHubè¯»å–READMEç‰ˆæœ¬å¤±è´¥: {e}")
        
        # å¤±è´¥æ—¶è¿”å›Noneï¼Œè®©è°ƒç”¨æ–¹ä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬å·ä½œä¸ºå¤‡ç”¨
        return None
    
    def get_current_version(self):
        """è·å–å½“å‰ç‰ˆæœ¬ï¼šæ ¼å¼ v3.7 (commit)"""
        version = self.get_current_version_from_readme()  # v3.7 æˆ– v3.7.1
        commit_hash = self.get_local_commit_hash()
        
        if commit_hash:
            return f"{version} ({commit_hash})"
        else:
            return version
    
    def get_local_commit_hash(self):
        """è·å–å½“å‰ä»£ç å¯¹åº”çš„commitæ ‡è¯†ã€‚
        ä¼˜å…ˆè¯»å– data/last_update.jsonï¼ˆZIPæ›´æ–°ä¼šå†™å…¥å‡†ç¡®commitï¼‰ï¼Œå¦åˆ™å›é€€åˆ° .git HEADã€‚
        """
        # 1) ä¼˜å…ˆ last_update.jsonï¼ˆZIPè·¯å¾„ä¼šå†™çœŸå®commitï¼‰
        try:
            state_path = os.path.join('data', 'last_update.json')
            if os.path.exists(state_path):
                with open(state_path, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                    commit = info.get('commit')
                    if commit:
                        return commit[:7]
        except Exception as e:
            logging.warning(f"è¯»å–ä¸Šæ¬¡æ›´æ–°è®°å½•å¤±è´¥: {e}")

        # 2) å›é€€åˆ°git HEAD
        try:
            result = subprocess.run(
                ['git', 'rev-parse', 'HEAD'],
                capture_output=True,
                text=True,
                cwd='.'
            )
            if result.returncode == 0:
                return result.stdout.strip()[:7]
        except Exception as e:
            logging.error(f"è·å–æœ¬åœ°commitå¤±è´¥: {e}")
        return None
    
    def get_latest_commit_info(self):
        """ä»GitHubè·å–æœ€æ–°commitä¿¡æ¯"""
        try:
            headers = {}
            github_token = os.getenv('GITHUB_TOKEN')
            if github_token:
                headers['Authorization'] = f'token {github_token}'
            
            url = f"{self.github_api}/commits/{self.branch}"
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'sha': data['sha'][:7],
                    'message': data['commit']['message'].split('\n')[0],
                    'date': data['commit']['author']['date'],
                    'author': data['commit']['author']['name']
                }
        except Exception as e:
            logging.error(f"è·å–è¿œç¨‹ç‰ˆæœ¬å¤±è´¥: {e}")
        return None
    
    def get_latest_release(self):
        """ä»GitHubè·å–æœ€æ–°Releaseç‰ˆæœ¬"""
        try:
            headers = {}
            github_token = os.getenv('GITHUB_TOKEN')
            if github_token:
                headers['Authorization'] = f'token {github_token}'
            
            url = f"{self.github_api}/releases/latest"
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    'version': data['tag_name'],
                    'name': data['name'],
                    'body': data['body'],
                    'published_at': data['published_at']
                }
        except Exception as e:
            logging.warning(f"è·å–Releaseä¿¡æ¯å¤±è´¥: {e}")
        return None
    
    def check_update(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°ï¼ˆä¼˜å…ˆä½¿ç”¨ Release ç‰ˆæœ¬å¯¹æ¯”ï¼›æ—  Release å†å›é€€åˆ° commit å¯¹æ¯”ï¼‰"""
        try:
            current_version = self.get_current_version()
            local_hash = self.get_local_commit_hash()

            # ä¼˜å…ˆè·å– Release ä¿¡æ¯
            release_info = self.get_latest_release()
            if release_info and release_info.get('version'):
                # åŒæ—¶ä¹Ÿè¿”å›æœ€è¿‘ä¸€æ¬¡æäº¤ä¿¡æ¯ç”¨äºå‚è€ƒ
                remote_info = self.get_latest_commit_info() or {}
                remote_commit = remote_info.get('sha', '')
                
                # ğŸ”§ ä¿®å¤ï¼šä»GitHubè¿œç¨‹è¯»å–æœ€æ–°ç‰ˆæœ¬å·ï¼Œè€Œä¸æ˜¯æœ¬åœ°README
                remote_version = self.get_remote_version_from_readme()
                if not remote_version:
                    # å¦‚æœè·å–å¤±è´¥ï¼Œé™çº§ä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬å·
                    remote_version = self.get_current_version_from_readme()
                    logging.warning("æ— æ³•è·å–è¿œç¨‹ç‰ˆæœ¬å·ï¼Œä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬å·ä½œä¸ºå‚è€ƒ")
                
                # æ„å»ºæœ€æ–°ç‰ˆæœ¬å·ï¼švX.X.X (commit)
                latest_version = f"{remote_version} ({remote_commit})" if remote_commit else remote_version
                
                has_update = (current_version != latest_version)
                return {
                    'success': True,
                    'has_update': has_update,
                    'current_version': current_version,
                    'current_commit': local_hash or 'æœªçŸ¥',
                    'latest_version': latest_version,
                    'latest_commit': remote_commit,
                    'latest_message': remote_info.get('message'),
                    'latest_date': remote_info.get('date'),
                    'latest_release': release_info
                }

            # æ—  Release æ—¶å›é€€åˆ° commit å¯¹æ¯”
            remote_info = self.get_latest_commit_info()
            if not remote_info:
                return {
                    'success': False,
                    'message': 'æ— æ³•è¿æ¥åˆ°GitHubï¼Œè¯·æ£€æŸ¥ç½‘ç»œ'
                }
            remote_commit = remote_info['sha']
            
            # ğŸ”§ ä¿®å¤ï¼šä»GitHubè¿œç¨‹è¯»å–æœ€æ–°ç‰ˆæœ¬å·ï¼Œè€Œä¸æ˜¯æœ¬åœ°README
            remote_version = self.get_remote_version_from_readme()
            if not remote_version:
                # å¦‚æœè·å–å¤±è´¥ï¼Œé™çº§ä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬å·
                remote_version = self.get_current_version_from_readme()
                logging.warning("æ— æ³•è·å–è¿œç¨‹ç‰ˆæœ¬å·ï¼Œä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬å·ä½œä¸ºå‚è€ƒ")
            
            # æ„å»ºæœ€æ–°ç‰ˆæœ¬å·ï¼švX.X.X (commit)
            latest_version = f"{remote_version} ({remote_commit})"
            
            has_update = local_hash != remote_commit if local_hash else True
            return {
                'success': True,
                'has_update': has_update,
                'current_version': current_version,
                'current_commit': local_hash or 'æœªçŸ¥',
                'latest_version': latest_version,
                'latest_commit': remote_commit,
                'latest_message': remote_info['message'],
                'latest_date': remote_info['date'],
                'latest_release': None
            }
        except Exception as e:
            logging.error(f"æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'æ£€æŸ¥æ›´æ–°å¤±è´¥: {str(e)}'
            }
    
    def backup_config(self):
        """å¤‡ä»½é…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists('config.json'):
                shutil.copy2('config.json', 'config.json.backup')
                logging.info("é…ç½®æ–‡ä»¶å·²å¤‡ä»½")
                return True
        except Exception as e:
            logging.error(f"å¤‡ä»½é…ç½®å¤±è´¥: {e}")
        return False
    
    def restore_config(self):
        """æ¢å¤é…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists('config.json.backup'):
                shutil.copy2('config.json.backup', 'config.json')
                logging.info("é…ç½®æ–‡ä»¶å·²æ¢å¤")
                return True
        except Exception as e:
            logging.error(f"æ¢å¤é…ç½®å¤±è´¥: {e}")
        return False
    
    def is_git_repo(self):
        """æ£€æŸ¥æ˜¯å¦ä¸ºGitä»“åº“"""
        return os.path.exists('.git')
    
    def init_git_repo(self):
        """åˆå§‹åŒ–Gitä»“åº“"""
        try:
            if not self.is_git_repo():
                logging.info("åˆå§‹åŒ–Gitä»“åº“...")
                
                subprocess.run(['git', 'init'], check=True, stdin=subprocess.DEVNULL)
                
                # é…ç½®Gitç¦ç”¨å‡­æ®
                subprocess.run(['git', 'config', 'credential.helper', ''], check=True)
                
                # æ·»åŠ è¿œç¨‹ä»“åº“
                github_token = os.getenv('GITHUB_TOKEN', '')
                if github_token:
                    logging.info("ä½¿ç”¨GitHub Tokenè¿›è¡Œè®¤è¯")
                    remote_url = f"https://{github_token}@github.com/{self.repo_owner}/{self.repo_name}.git"
                else:
                    logging.info("ä½¿ç”¨å…¬å¼€è®¿é—®æ¨¡å¼ï¼ˆæ— è®¤è¯ï¼‰")
                    remote_url = f"https://github.com/{self.repo_owner}/{self.repo_name}.git"
                
                subprocess.run(['git', 'remote', 'add', 'origin', remote_url], check=True)
                subprocess.run(['git', 'fetch', 'origin'], check=True, stdin=subprocess.DEVNULL)
                subprocess.run(['git', 'checkout', '-b', self.branch, f'origin/{self.branch}'], check=True, stdin=subprocess.DEVNULL)
                
                logging.info("Gitä»“åº“åˆå§‹åŒ–å®Œæˆ")
                return True
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Gitä»“åº“å¤±è´¥: {e}")
        return False
    
    def do_update(self):
        """æ‰§è¡Œæ›´æ–°"""
        try:
            logging.info("=" * 60)
            logging.info("å¼€å§‹æ‰§è¡Œç³»ç»Ÿæ›´æ–°...")
            logging.info("=" * 60)
            
            # å¤‡ä»½é…ç½®æ–‡ä»¶
            logging.info("æ­£åœ¨å¤‡ä»½é…ç½®æ–‡ä»¶...")
            if not self.backup_config():
                logging.error("é…ç½®æ–‡ä»¶å¤‡ä»½å¤±è´¥")
                return {
                    'success': False,
                    'message': 'å¤‡ä»½é…ç½®æ–‡ä»¶å¤±è´¥'
                }
            logging.info("é…ç½®æ–‡ä»¶å¤‡ä»½æˆåŠŸ")
            
            # ç›´æ¥èµ° ZIP é•œåƒ/API æ›´æ–°ï¼ˆä¸å†ä½¿ç”¨ gitï¼‰
            logging.info("æ­£åœ¨é€šè¿‡ZIPæ–¹å¼è·å–æœ€æ–°ä»£ç ...")
            fb = self._fallback_update_via_zip()
            
            if fb.get('success'):
                logging.info("ZIPæ›´æ–°æˆåŠŸ")
                # æ¢å¤é…ç½®æ–‡ä»¶
                self.restore_config()
                # ä¸å‰ç«¯å¯¹é½ï¼šè¿”å›é€šç”¨æˆåŠŸä¿¡æ¯ï¼Œä¸æš´éœ²å›é€€æ¥æº
                fb['message'] = 'æ›´æ–°æˆåŠŸ'
                fb.pop('from', None)
                logging.info("=" * 60)
                logging.info("ç³»ç»Ÿæ›´æ–°å®Œæˆï¼")
                logging.info("=" * 60)
                return fb
            else:
                error_msg = fb.get('message', 'æ›´æ–°å¤±è´¥')
                logging.error(f"ZIPæ›´æ–°å¤±è´¥: {error_msg}")
                # å°è¯•æ¢å¤é…ç½®
                self.restore_config()
                return {
                    'success': False,
                    'message': error_msg
                }
            
        except Exception as e:
            logging.error(f"æ›´æ–°è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            # å°è¯•æ¢å¤é…ç½®
            try:
                self.restore_config()
            except Exception as restore_err:
                logging.error(f"æ¢å¤é…ç½®å¤±è´¥: {restore_err}")
            
            return {
                'success': False,
                'message': f'æ›´æ–°å¤±è´¥: {str(e)}'
            }
    
    def _fallback_update_via_zip(self):
        """ä½¿ç”¨ZIPä¸‹è½½+è¦†ç›–æ–¹å¼æ›´æ–°ï¼ˆæ”¯æŒå…¬å¼€é•œåƒä¸ç§æœ‰ä»“åº“zipballï¼‰ã€‚"""
        try:
            def download_with_requests(url: str, out_path: str, headers: dict | None = None) -> bool:
                try:
                    logging.info(f"å°è¯•ä½¿ç”¨requestsä¸‹è½½: {url}")
                    resp = requests.get(url, timeout=60, stream=True, headers=headers or {})
                    if resp.status_code == 200:
                        total_size = 0
                        with open(out_path, 'wb') as f:
                            for chunk in resp.iter_content(chunk_size=1024 * 256):
                                if chunk:
                                    f.write(chunk)
                                    total_size += len(chunk)
                        logging.info(f"requestsä¸‹è½½æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.2f} MB")
                        return True
                    logging.warning(f"requests ä¸‹è½½å¤±è´¥: {url} -> HTTP {resp.status_code}")
                except Exception as e:
                    logging.warning(f"requests ä¸‹è½½å¼‚å¸¸: {e}")
                return False

            def download_with_curl(url: str, out_path: str, headers: dict | None = None) -> bool:
                try:
                    logging.info(f"å°è¯•ä½¿ç”¨curlä¸‹è½½: {url}")
                    cmd = ['curl', '-L', '-sS', '--fail', '-o', out_path]
                    if headers:
                        for k, v in headers.items():
                            cmd.extend(['-H', f"{k}: {v}"])
                    cmd.append(url)
                    r = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
                    if r.returncode == 0 and os.path.exists(out_path) and os.path.getsize(out_path) > 0:
                        size = os.path.getsize(out_path)
                        logging.info(f"curlä¸‹è½½æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {size / 1024 / 1024:.2f} MB")
                        return True
                    logging.warning(f"curl ä¸‹è½½å¤±è´¥: {url} -> è¿”å›ç {r.returncode}, é”™è¯¯: {r.stderr.strip()}")
                except subprocess.TimeoutExpired:
                    logging.error("curlä¸‹è½½è¶…æ—¶ï¼ˆ120ç§’ï¼‰")
                except Exception as ce:
                    logging.warning(f"curl ä¸‹è½½å¼‚å¸¸: {ce}")
                return False

            # 1) ç§æœ‰ä»“åº“ï¼šä¼˜å…ˆ GitHub API zipball
            github_token = os.getenv('GITHUB_TOKEN')
            if github_token:
                logging.info("æ£€æµ‹åˆ°GITHUB_TOKENï¼Œå°è¯•ä½¿ç”¨GitHub APIä¸‹è½½...")
                api_url = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}/zipball/{self.branch}"
                headers = {'Authorization': f'token {github_token}', 'Accept': 'application/vnd.github+json'}
                with tempfile.TemporaryDirectory() as td:
                    zip_path = os.path.join(td, 'repo.zip')
                    if download_with_requests(api_url, zip_path, headers) or download_with_curl(api_url, zip_path, headers):
                        logging.info("GitHub APIæ–¹å¼ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹è§£å‹...")
                        return self._extract_and_overlay(zip_path)
                logging.warning("GitHub APIæ–¹å¼ä¸‹è½½å¤±è´¥ï¼Œå°è¯•å…¬å¼€ä¸‹è½½...")
            else:
                logging.info("æœªè®¾ç½®GITHUB_TOKENï¼Œä½¿ç”¨å…¬å¼€ä¸‹è½½æ–¹å¼")

            # 2) GitHubå®˜æ–¹ä¸‹è½½åœ°å€
            official_url = f"https://github.com/{self.repo_owner}/{self.repo_name}/archive/refs/heads/{self.branch}.zip"
            
            last_error = None
            logging.info(f"å°è¯•ä»GitHubå®˜æ–¹åœ°å€ä¸‹è½½: {official_url}")
            for url in [official_url]:
                try:
                    with tempfile.TemporaryDirectory() as td:
                        zip_path = os.path.join(td, 'repo.zip')
                        ok = download_with_requests(url, zip_path) or download_with_curl(url, zip_path)
                        if not ok:
                            last_error = 'ä¸‹è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–GitHubè®¿é—®å—é™'
                            continue
                        logging.info("ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹è§£å‹å’Œè¦†ç›–æ–‡ä»¶...")
                        return self._extract_and_overlay(zip_path)
                except Exception as e:
                    last_error = str(e)
                    logging.error(f"ä¸‹è½½æˆ–è§£å‹è¿‡ç¨‹å¼‚å¸¸: {e}", exc_info=True)
                    continue

            return {'success': False, 'message': f'GitHub ZIPæ›´æ–°å¤±è´¥: {last_error or "æœªçŸ¥é”™è¯¯"}'}
        except Exception as e:
            logging.error(f"ZIPå›é€€æ›´æ–°å¼‚å¸¸: {e}", exc_info=True)
            return {'success': False, 'message': f'ZIPå›é€€æ›´æ–°å¼‚å¸¸: {str(e)}'}

    def _extract_and_overlay(self, zip_path: str) -> dict:
        with tempfile.TemporaryDirectory() as td:
            with zipfile.ZipFile(zip_path) as zf:
                zf.extractall(td)

            # æ‰¾åˆ°è§£å‹åçš„æ ¹ç›®å½•
            entries = [p for p in os.listdir(td) if os.path.isdir(os.path.join(td, p))]
            src_root = None
            for p in entries:
                if p.lower().startswith(self.repo_name.lower()):
                    src_root = os.path.join(td, p)
                    break
            if not src_root and entries:
                src_root = os.path.join(td, entries[0])
            if not src_root:
                return {'success': False, 'message': 'ZIPå†…å®¹è§£æå¤±è´¥'}

            # ä»è§£å‹ç›®å½•åå°è¯•è§£æcommitï¼ˆzipball/codeload é€šå¸¸åŒ…å«çŸ­/é•¿shaï¼‰
            parsed_commit = None
            try:
                import re
                base = os.path.basename(src_root)
                m = re.search(r'-([0-9a-fA-F]{7,40})$', base)
                if m:
                    parsed_commit = m.group(1)[:7]
            except Exception:
                pass

            keep_files = {'config.json'}
            keep_dirs = {'logs', 'debug', 'data', '.git'}

            for root, dirs, files in os.walk(src_root):
                rel = os.path.relpath(root, src_root)
                if rel == '.':
                    rel = ''
                parts = rel.split(os.sep) if rel else []
                if parts and parts[0] in keep_dirs:
                    continue

                dest_dir = os.path.join('.', rel) if rel else '.'
                os.makedirs(dest_dir, exist_ok=True)

                for filename in files:
                    if filename in keep_files:
                        continue
                    src_file = os.path.join(root, filename)
                    dst_file = os.path.join(dest_dir, filename)
                    shutil.copy2(src_file, dst_file)

            logging.info("ZIPæ›´æ–°å®Œæˆ")
            # è®°å½•æœ¬æ¬¡æ›´æ–°æ¥æºä¸æ—¶é—´ï¼Œä¾¿äºégitç¯å¢ƒæ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
            try:
                os.makedirs('data', exist_ok=True)
                with open(os.path.join('data', 'last_update.json'), 'w', encoding='utf-8') as f:
                    json.dump({
                        'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'source': 'zip',
                        'commit': parsed_commit or 'zip'
                    }, f, ensure_ascii=False)
            except Exception:
                pass

            # è·å–å®Œæ•´ç‰ˆæœ¬å·ï¼šv3.7.1 (commit)
            new_version = self.get_current_version()
            new_commit = parsed_commit or 'zip'
            return {
                'success': True,
                'message': 'æ›´æ–°æˆåŠŸ',
                'new_version': new_version,
                'new_commit': new_commit,
                'need_restart': True
            }

    def get_update_log(self, limit=10):
        """è·å–æ›´æ–°æ—¥å¿—ï¼ˆåŒ…å«å®Œæ•´æäº¤å†…å®¹ï¼‰ã€‚
        é€»è¾‘ï¼šä¼˜å…ˆæœ¬åœ° gitï¼›å¦‚æœ¬åœ°æœ€æ–°æäº¤ä¸è¿œç«¯ä¸ä¸€è‡´ï¼Œæ”¹ç”¨ GitHub APIï¼›æœ¬åœ°ä¸å¯ç”¨ä¹Ÿç”¨ APIã€‚
        """
        def _from_github_api(n: int):
            try:
                headers = {'User-Agent': 'aw98tang-update-client'}
                github_token = os.getenv('GITHUB_TOKEN')
                if github_token:
                    headers['Authorization'] = f'token {github_token}'
                url = f"{self.github_api}/commits?sha={self.branch}&per_page={max(1,int(n))}"
                resp = requests.get(url, headers=headers, timeout=10)
                if resp.status_code == 200:
                    logs = []
                    for item in resp.json():
                        logs.append({
                            'hash': item.get('sha','')[:7],
                            'author': (item.get('commit',{}).get('author',{}) or {}).get('name',''),
                            'date': (item.get('commit',{}).get('author',{}) or {}).get('date',''),
                            'message': (item.get('commit',{}) or {}).get('message','')
                        })
                    return {'success': True, 'logs': logs}
                logging.error(f"GitHub API è·å–æ—¥å¿—å¤±è´¥: HTTP {resp.status_code}")
            except Exception as e:
                logging.error(f"GitHub API è·å–æ—¥å¿—å¼‚å¸¸: {e}")
            return {'success': False, 'logs': []}

        # è¿œç«¯æœ€æ–°æäº¤SHA
        remote_info = self.get_latest_commit_info() or {}
        remote_sha = remote_info.get('sha')

        # 1) è¯»å–æœ¬åœ° git æ—¥å¿—
        try:
            record_sep = '\x1e'
            field_sep = '\x1f'
            pretty = f"%h%x1f%an%x1f%ar%x1f%B%x1e"
            result = subprocess.run(
                ['git', 'log', f'-{limit}', f'--pretty=format:{pretty}'],
                capture_output=True,
                text=True
            )
            if result.returncode == 0 and result.stdout.strip():
                raw = result.stdout
                logs = []
                for rec in raw.split(record_sep):
                    if not rec.strip():
                        continue
                    fields = rec.split(field_sep)
                    if len(fields) >= 4:
                        commit_hash, author, rel_date, message = fields[0], fields[1], fields[2], field_sep.join(fields[3:])
                        logs.append({
                            'hash': commit_hash.strip(),
                            'author': author.strip(),
                            'date': rel_date.strip(),
                            'message': message.strip()
                        })
                # å¦‚æœæœ¬åœ°æœ€æ–°ä¸è¿œç«¯ä¸åŒï¼Œåˆ™æ”¹ç”¨è¿œç«¯
                if logs and remote_sha and logs[0]['hash'] != remote_sha:
                    api_logs = _from_github_api(limit)
                    if api_logs['success']:
                        return api_logs
                if logs:
                    return {'success': True, 'logs': logs}
        except Exception as e:
            logging.warning(f"æœ¬åœ°gitæ—¥å¿—ä¸å¯ç”¨: {e}")

        # 2) ç›´æ¥ç”¨è¿œç«¯
        return _from_github_api(limit)


